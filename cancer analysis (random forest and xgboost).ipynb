{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whenever we are working with categorical feature, we must encode it as numbers. \n",
    "#For this problem, weâ€™ll set malignant to 1 and benign to 0.\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, binary_encoded_y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 60)\n",
    "y = list(map(lambda x: x / 2 + (x // 10) % 2 * 20 * x / 5 + np.random.random() * 10, x))\n",
    "x = pd.DataFrame({'x': x})\n",
    "\n",
    "# Plot mock data\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = linear_model.LinearRegression()\n",
    "\n",
    "linear_regressor.fit(x, y)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, linear_regressor.predict(x), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Residuals $(y - \\hat{y})$ of Linear Regression model\")\n",
    "plt.scatter(x, y - linear_regressor.predict(x), color='brown')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 1,\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 1,\n",
    "    'criterion': 'mse'\n",
    "}\n",
    "\n",
    "gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "gradient_boosting_regressor.fit(x, y)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Gradient Boosting model (1 estimators, Single tree split)')\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, gradient_boosting_regressor.predict(x), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Residuals of Gradient boosting model (1 estimator, Single tree split)')\n",
    "plt.scatter(x, y - gradient_boosting_regressor.predict(x), color='brown')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['n_estimators'] = 2\n",
    "\n",
    "gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "gradient_boosting_regressor.fit(x, y)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Gradient Boosting model (1 estimators, Single tree split)')\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, gradient_boosting_regressor.predict(x), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "for idx, n_estimators in enumerate([5, 10, 20, 50]):\n",
    "    params['n_estimators'] = n_estimators\n",
    "\n",
    "    gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "    gradient_boosting_regressor.fit(x, y)\n",
    "    subplot = ax[idx // 2][idx % 2]\n",
    "    subplot.set_title('Gradient Boosting model ({} estimators, Single tree split)'.format(n_estimators))\n",
    "    subplot.scatter(x, y)\n",
    "    subplot.plot(x, gradient_boosting_regressor.predict(x), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Gradient Boosting (GB)\n",
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "gb.fit(train_X, train_y)\n",
    "predictions = gb.predict(test_X)\n",
    "confusion_matrix(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of XGB\n",
    "xgb=XGBClassifier(learning_rate=0.1,n_estimators=500,min_child_weight=1,gamma=0,max_depth=3,\n",
    "                        scale_pos_weight=1,max_delta_step=0,\n",
    "                   colsample_bylevel= 0.5, colsample_bytree= 0.6, subsample= 1.0,\n",
    "                  reg_lambda=1.5,reg_alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb.predict(test_X)\n",
    "confusion_matrix(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
